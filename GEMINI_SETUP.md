# ü§ñ Gu√≠a de Configuraci√≥n Gemini 2.5 Flash Lite

Esta gu√≠a explica c√≥mo configurar y usar Gemini 2.5 Flash Lite como alternativa a Llama 3.2 1B en tu chatbot RAG.

## üöÄ Configuraci√≥n R√°pida

### 1. Obtener API Key de Google AI

1. Visita [Google AI Studio](https://makersuite.google.com/app/apikey)
2. Inicia sesi√≥n con tu cuenta de Google
3. Crea un nuevo proyecto (si no tienes uno)
4. Genera una nueva API Key
5. Copia la API Key (formato: `AIza...`)

### 2. Configurar Variables de Entorno

**Opci√≥n A: Archivo .env (Recomendado)**
```bash
# Crear archivo .env en la ra√≠z del proyecto
echo "GOOGLE_API_KEY=tu_api_key_aqui" >> .env

# Ejemplo
echo "GOOGLE_API_KEY=AIzaSyC123...xyz789" >> .env
```

**Opci√≥n B: Variable de sistema**
```bash
# Linux/Mac
export GOOGLE_API_KEY="tu_api_key_aqui"

# Windows
set GOOGLE_API_KEY=tu_api_key_aqui
```

### 3. Reiniciar el Sistema

```bash
# Reiniciar solo la aplicaci√≥n
docker compose restart app

# O reiniciar todo el stack
docker compose down
docker compose up -d
```

## üéØ Usar Gemini en la Interfaz Web

1. **Accede a la interfaz:** http://localhost:7860
2. **Localiza el selector de proveedor** en la parte superior
3. **Selecciona "google"** del radio button "Proveedor LLM"
4. **Verifica el cambio** en el campo "Estado del modelo"
   - ‚úÖ √âxito: "Modelo actual: gemini-2.5-flash-lite (google)"
   - ‚ùå Error: "Error al cambiar a google. Usando: llama3.2:1b (ollama)"

## ‚ö° Ventajas de Gemini 2.5 Flash Lite

### Rendimiento
- **Ultra velocidad**: Respuestas en <1 segundo
- **Sin descarga**: No requiere descargar GB de modelos
- **Baja latencia**: Infraestructura optimizada de Google

### Capacidades
- **Multimodal**: Soporta texto e im√°genes (futuras funcionalidades)
- **Contexto largo**: Hasta 1M tokens de contexto
- **Actualizado**: Modelo m√°s reciente de Google AI

### Recursos
- **Sin consumo local**: Libera RAM y CPU del servidor
- **Escalabilidad**: No limitado por hardware local
- **Disponibilidad**: 99.9% uptime garantizado por Google

## üîÑ Cambio Din√°mico Entre Modelos

### Desde la Interfaz Web
- **Cambiar a Gemini**: Selecciona "google" ‚Üí Cambio autom√°tico
- **Volver a Ollama**: Selecciona "ollama" ‚Üí Vuelve a llama3.2:1b

### Configuraci√≥n por Defecto
```yaml
# En docker-compose.yml
environment:
  LLM_PROVIDER: ollama          # Cambiar a "google" para Gemini por defecto
  LLM_MODEL: llama3.2:1b       # Solo aplica cuando provider=ollama
  GOOGLE_API_KEY: "${GOOGLE_API_KEY:-}"  # Toma del .env
```

## üõ†Ô∏è Troubleshooting

### Error: "Google API key not found"
```bash
# Verificar que la variable existe
echo $GOOGLE_API_KEY

# Verificar el archivo .env
cat .env | grep GOOGLE_API_KEY

# Reiniciar despu√©s de configurar
docker compose restart app
```

### Error: "Failed to switch to google"
```bash
# Verificar logs
docker compose logs app | grep -i google

# Posibles causas:
# 1. API Key inv√°lida o expirada
# 2. L√≠mites de cuota excedidos
# 3. Problemas de conectividad

# Soluci√≥n: Verificar API Key en Google AI Studio
```

### Error: "No response from model"
```bash
# Verificar conectividad
curl -H "x-goog-api-key: tu_api_key" \
     -H "Content-Type: application/json" \
     -X POST \
     -d '{"contents":[{"parts":[{"text":"Hello"}]}]}' \
     "https://generativelanguage.googleapis.com/v1/models/gemini-2.5-flash-lite:generateContent"

# Si falla, verificar:
# 1. API Key correcta
# 2. Modelo disponible en tu regi√≥n
# 3. Cuotas de la API
```

## üí∞ Consideraciones de Costo

### Google AI Studio - Nivel Gratuito
- **15 RPM (requests por minuto)**
- **1M tokens por d√≠a** 
- **Gratis hasta l√≠mites**

### Uso Estimado
```
Consulta t√≠pica RAG: ~500 tokens
Respuesta t√≠pica: ~200 tokens
Total por consulta: ~700 tokens

Con l√≠mite gratuito:
1,000,000 √∑ 700 = ~1,428 consultas/d√≠a
```

### Optimizaci√≥n de Costos
- **Usa contexto m√≠nimo**: Solo documentos relevantes
- **Historial limitado**: Configuraci√≥n autom√°tica (6 turnos)
- **Respuestas concisas**: Temperature=0.05 configurado

## üîí Seguridad

### Protecci√≥n de API Keys
```bash
# Nunca versionar archivos con keys
echo ".env" >> .gitignore

# Usar variables de entorno en producci√≥n
# No hardcodear keys en docker-compose.yml
```

### Mejores Pr√°cticas
- **Rotar API Keys** regularmente
- **Monitorear uso** en Google AI Studio
- **Configurar alertas** de cuota
- **Usar l√≠mites** por aplicaci√≥n

## üìä Comparativa: Gemini vs Llama 3.2 1B

| Aspecto | Gemini 2.5 Flash Lite | Llama 3.2 1B |
|---------|------------------------|---------------|
| **Velocidad** | <1s (nube) | ~2s (local) |
| **Instalaci√≥n** | Solo API key | ~1.3GB descarga |
| **RAM Local** | 0MB | ~2GB |
| **Calidad** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |
| **Costo** | Gratis/Pago API | Gratis total |
| **Privacidad** | Nube Google | 100% local |
| **Disponibilidad** | Internet requerido | Funciona offline |

## ‚úÖ Verificaci√≥n de Configuraci√≥n

```bash
# Script de verificaci√≥n
curl -s http://localhost:8080/status | jq '.services'

# Verificar modelo activo desde logs
docker compose logs app | tail -20 | grep -i "model\|provider"

# Test b√°sico con ambos modelos
# 1. Selecciona ollama ‚Üí Haz una pregunta
# 2. Selecciona google ‚Üí Haz la misma pregunta
# 3. Compara velocidad y calidad
```

---

**¬øProblemas?** Consulta los logs: `docker compose logs app | grep -E "(ERROR|WARN|google|gemini)"`