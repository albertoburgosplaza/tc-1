
# Chatbot RAG con Google Gemini ‚Äî Microservicios con Docker Compose

Sistema de chatbot con Retrieval Augmented Generation (RAG) **multimodal** que permite consultar documentos PDF con texto e im√°genes, y ejecutar c√≥digo Python de forma segura. Utiliza Google Gemini como modelo de lenguaje, Jina embeddings para procesamiento multimodal y una arquitectura de microservicios con Docker Compose para facilitar el despliegue y escalabilidad.

## üèóÔ∏è Arquitectura

**Servicios principales:**
- **qdrant**: Base de datos vectorial para almacenamiento de embeddings
- **pyexec**: Microservicio para ejecutar expresiones Python de forma segura
- **app**: Interfaz web con Gradio + LangChain + Google Gemini que orquesta RAG
- **ingest**: Job de procesamiento para ingestar PDFs en Qdrant con embeddings multimodales de Jina (texto + im√°genes)

## ‚ö° Inicio R√°pido

### Requisitos del Sistema

**Obligatorios:**
- Docker (versi√≥n 20.10 o superior)
- Docker Compose (versi√≥n 2.0 o superior)
- **Google API Key** (para acceso a Gemini LLM)
- **Jina API Key** (para embeddings y reranking)
- M√≠nimo 2GB RAM disponible
- Al menos 2GB de espacio en disco

**Verificar instalaci√≥n:**
```bash
docker --version && docker compose version
```

### Instalaci√≥n Autom√°tica

Para un setup completo en menos de 5 minutos:

1. **Configurar API Keys:**
   ```bash
   export GOOGLE_API_KEY="tu_google_api_key_aqui"
   export JINA_API_KEY="tu_jina_api_key_aqui"
   ```

2. **Clonar y preparar:**
   ```bash
   git clone <repository-url>
   cd turingchallenge-reto-1
   chmod +x setup.sh
   ./setup.sh
   ```

### Instalaci√≥n Manual

#### 1. Preparar Documentos

Crear carpeta de documentos y a√±adir PDFs:
```bash
# Crear carpeta
mkdir -p docs

# A√±adir tus PDFs (ejemplos)
cp /ruta/a/tus/*.pdf docs/
# O descargar documentos de ejemplo
wget -P docs/ "https://example.com/sample.pdf"
```

**Limitaciones:**
- Tama√±o m√°ximo por PDF: 100MB
- Formatos soportados: PDF √∫nicamente
- M√≠nimo contenido por documento: 10 caracteres
- **Im√°genes:** M√°ximo 1024x1024px, 5MB por imagen
- **Procesamiento:** Las im√°genes se extraen autom√°ticamente durante la ingesta

#### 2. Configurar API Keys

```bash
# Configurar variables de entorno
export GOOGLE_API_KEY="tu_google_api_key_aqui"
export JINA_API_KEY="tu_jina_api_key_aqui"

# O crear archivo .env
echo "GOOGLE_API_KEY=tu_google_api_key_aqui" > .env
echo "JINA_API_KEY=tu_jina_api_key_aqui" >> .env
```

**C√≥mo obtener las API Keys:**

**Google API Key (para Gemini LLM):**
1. Ir a [Google AI Studio](https://makersuite.google.com/app/apikey)
2. Crear una nueva API key
3. Habilitar Generative AI API

**Jina API Key (para embeddings y reranking):**
1. Ir a [Jina AI](https://jina.ai/)
2. Crear una cuenta gratuita
3. Obtener tu API key desde el dashboard
4. Verificar los l√≠mites en [Jina Pricing](https://jina.ai/pricing)

#### 3. Levantar Servicios

```bash
# Construir y levantar servicios
docker compose up -d --build qdrant pyexec app

# Verificar que los servicios est√°n saludables
docker compose ps
```

**Tiempo estimado:** 3-5 minutos (primera vez)

#### 4. Procesar Documentos

```bash
# Ejecutar ingesta completa de todos los PDFs
docker compose run --rm ingest

# O procesar un solo PDF sin rehacer toda la colecci√≥n
python add_single_pdf.py docs/nuevo_documento.pdf

# Verificar ingesta exitosa
docker logs ingest
```

**Tiempo estimado:** 1-5 minutos (seg√∫n cantidad de PDFs)

**üìù Procesamiento individual:**
Para a√±adir documentos nuevos sin reprocesar toda la colecci√≥n, utiliza el script `add_single_pdf.py`:
- ‚úÖ M√°s r√°pido para documentos individuales
- ‚úÖ No requiere Docker (pero s√≠ las variables de entorno)
- ‚úÖ Validaciones autom√°ticas de formato y conexi√≥n
- ‚úÖ Preserva documentos ya procesados

#### 5. Acceder a la Interfaz

- **Interfaz principal:** http://localhost:7860
- **API health check:** http://localhost:8080/health
- **Qdrant dashboard:** http://localhost:6333/dashboard

## üéØ Gu√≠a de Uso

### Consultas RAG (Documentos)

**Ejemplos de preguntas:**
```
- "¬øQu√© dice el documento sobre inteligencia artificial?"
- "Resume los puntos principales del cap√≠tulo 3"
- "¬øCu√°les son las conclusiones del estudio?"
- "Compara las ventajas de Random Forest vs Redes Neuronales"
```

**Caracter√≠sticas:**
- üìù **Citas mejoradas:** Referencias inline con documento, p√°gina y contexto detallado
- üîç **B√∫squeda sem√°ntica:** Vectores multimodales de Jina para alta precisi√≥n
- üåç **Soporte multiling√ºe:** Consultas en m√∫ltiples idiomas nativamente
- üîÑ **An√°lisis comparativo:** Entre documentos y secci√≥nes
- üéØ **Reranking inteligente:** Jina Rerank optimiza relevancia de resultados
- üìä **Mapeo de fuentes:** Identificaci√≥n precisa de documentos citados

### Ejecuci√≥n de C√≥digo Python

**Sintaxis soportada:**
```python
# Operaciones matem√°ticas
python: (2+3)*10
python: import math; math.sqrt(16)

# An√°lisis estad√≠stico
python: import statistics; statistics.mean([1,2,3,4,5])

# An√°lisis de datos
python: [1,2,3,4,5]; sum(_)/len(_)

# Consultas en lenguaje natural
"Calcula la media de 1, 5, 10"
"¬øCu√°nto es 15% de 200?"
"Calcula el inter√©s compuesto de $5000 al 3.5% por 7 a√±os"
```

**Limitaciones de seguridad:**
- Timeout: 5 segundos
- M√°ximo 500 caracteres por expresi√≥n
- Sin acceso a archivos del sistema
- Bibliotecas limitadas (math, statistics, b√°sicas)

### Consultas Mixtas

Puedes combinar ambas funcionalidades:
```
"Seg√∫n el documento financiero, calcula el ROI si la inversi√≥n es de $100,000 y los ingresos son python: 150000 * 1.2"

"El paper menciona una muestra de 200 participantes. ¬øEs estad√≠sticamente significativo con un margen de error del 3.5%? python: 1.96/0.035**2 * 0.25"
```

### Consultas Multimodales (Texto + Im√°genes)

El sistema ahora soporta **RAG multimodal** que procesa tanto texto como im√°genes extra√≠das de los PDFs:

**Caracter√≠sticas multimodales:**
- üñºÔ∏è **Extracci√≥n de im√°genes:** Autom√°tica desde PDFs durante la ingesta
- üîç **B√∫squeda visual:** Encuentra im√°genes relevantes seg√∫n consultas de texto
- ü§ù **Contexto h√≠brido:** Combina informaci√≥n textual y visual en las respuestas
- üéØ **Reranking inteligente:** Jina Rerank mejora la relevancia de resultados mixtos

**Ejemplos de consultas multimodales:**
```
- "¬øQu√© gr√°ficos muestran la tendencia de ventas?"
- "Encuentra diagramas sobre arquitectura de microservicios"
- "Muestra las im√°genes relacionadas con el proceso de manufactura"
- "Compara las tablas de resultados experimentales"
- "¬øHay capturas de pantalla de la interfaz de usuario?"
```

**Configuraci√≥n multimodal:**
```yaml
ENABLE_IMAGE_INGEST: true              # Habilitar procesamiento de im√°genes
IMAGE_MAX_SIDE_PX: 1024                # Tama√±o m√°ximo de imagen (p√≠xeles)
IMAGE_MAX_BYTES: 5242880               # Tama√±o m√°ximo (5MB)
TOP_K_SEARCH: 50                       # B√∫squeda inicial
TOP_N_RERANK: 10                       # Resultados finales tras reranking
```

### Ejemplos Completos

Para ejemplos detallados con respuestas esperadas, consulta **[EXAMPLES.md](EXAMPLES.md)** que incluye:
- üìä Casos de an√°lisis financiero con c√°lculos
- üî¨ Validaci√≥n de datos de investigaci√≥n
- üí¨ Conversaciones multi-turno con memoria contextual
- üßÆ An√°lisis estad√≠stico de datasets
- ‚ö†Ô∏è Manejo de errores y casos l√≠mite

## ‚öôÔ∏è Configuraci√≥n Avanzada

### Variables de Entorno Principales

#### Servicio App
```yaml
# Configuraci√≥n del LLM (solo Google Gemini)
LLM_PROVIDER: google                     # √önico proveedor soportado
GOOGLE_API_KEY: "${GOOGLE_API_KEY}"      # API Key de Google AI (REQUERIDA)

# Configuraci√≥n de Qdrant
QDRANT_URL: http://qdrant:6333           # URL interna de Qdrant
COLLECTION_NAME: rag_multimodal          # Nombre de la colecci√≥n vectorial multimodal

# Configuraci√≥n de la interfaz
GRADIO_SERVER_NAME: 0.0.0.0             # Host de Gradio
GRADIO_SERVER_PORT: 7860                 # Puerto de Gradio

# Validaci√≥n de entrada
MAX_QUERY_LENGTH: 2000                   # M√°ximo caracteres por consulta
MIN_QUERY_LENGTH: 1                      # M√≠nimo caracteres por consulta

# Gesti√≥n de Memoria y Conversaciones
MAX_HISTORY_CHARS: 8000                  # L√≠mite de caracteres antes de resumir historial
SLIDING_WINDOW_TURNS: 6                  # Turnos recientes preservados tras resumen

# Integraci√≥n Python
PYEXEC_URL: http://pyexec:8001           # URL del servicio Python
```

#### Servicio PyExec
```yaml
PYEXEC_TIMEOUT_SEC: 5                    # Timeout para ejecuci√≥n Python
MAX_EXPR_LENGTH: 500                     # M√°ximo caracteres en expresi√≥n
MAX_EXPR_COMPLEXITY: 100                 # L√≠mite de complejidad AST
```

#### Servicio Ingest
```yaml
# Configuraci√≥n de embeddings (Jina)
EMBEDDING_MODEL: jina-embeddings-v4     # Modelo de Jina para embeddings
EMBEDDING_PROVIDER: jina                # Proveedor de embeddings
JINA_API_KEY: "${JINA_API_KEY}"          # API Key de Jina (REQUERIDA)
DOCUMENTS_DIR: /app/docs                # Carpeta interna de documentos

# Procesamiento de PDFs
MAX_PDF_SIZE_MB: 100                     # Tama√±o m√°ximo por PDF
CHUNK_SIZE: 1200                         # Tama√±o de chunks en caracteres
CHUNK_OVERLAP: 180                       # Solapamiento entre chunks
MIN_CONTENT_LENGTH: 10                   # Contenido m√≠nimo por chunk

# Configuraci√≥n multimodal
ENABLE_IMAGE_INGEST: true                # Habilitar extracci√≥n de im√°genes
IMAGE_MAX_SIDE_PX: 1024                  # Tama√±o m√°ximo de imagen (p√≠xeles)
IMAGE_MAX_BYTES: 5242880                 # Tama√±o m√°ximo de imagen (5MB)

# Configuraci√≥n de reranking y b√∫squeda
JINA_RERANK_MODEL: jina-rerank-m0        # Modelo de reranking de Jina
TOP_K_SEARCH: 50                         # Resultados iniciales de b√∫squeda
TOP_N_RERANK: 10                         # Resultados finales tras reranking
PARALLEL_RETRIEVAL: true                 # Habilitar recuperaci√≥n paralela
MAX_RETRIEVAL_WORKERS: 2                 # M√°ximo workers para procesamiento paralelo
```

### Modelo LLM Configurado

Este sistema utiliza √∫nicamente **Google Gemini 2.5 Flash Lite** como modelo de lenguaje:

**Caracter√≠sticas:**
- ‚ö° **Ultra velocidad:** Respuestas en milisegundos
- üåê **API-based:** Sin modelos locales, menor uso de recursos
- üîß **Pre-configurado:** Listo para usar con tu Google API Key
- üåç **Multileng√ºe:** Soporte nativo para m√∫ltiples idiomas

**Configuraci√≥n requerida:**
```bash
# API Keys necesarias
export GOOGLE_API_KEY="tu_google_api_key_aqui"    # Para Gemini LLM
export JINA_API_KEY="tu_jina_api_key_aqui"        # Para embeddings y reranking
```

### Modelo de Embeddings Configurado

El sistema utiliza **Jina `jina-embeddings-v4`** para generar embeddings:

**Caracter√≠sticas:**
- üìä **Alta calidad:** Embeddings de √∫ltima generaci√≥n optimizados para RAG multimodal
- üöÄ **R√°pido:** Generaci√≥n via API de Jina sin procesamiento local
- üîÑ **Consistente:** Embeddings estables entre sesiones
- üåç **Multimodal:** Soporte para texto e im√°genes con el mismo modelo

**Configuraci√≥n actual:**
```yaml
# En docker-compose.yml servicio ingest
EMBEDDING_MODEL: jina-embeddings-v4
EMBEDDING_PROVIDER: jina
JINA_API_KEY: "${JINA_API_KEY}"
```

**Reranker incluido:**
El sistema tambi√©n utiliza **Jina Rerank M0** para mejorar la relevancia de los resultados:
```yaml
JINA_RERANK_MODEL: jina-rerank-m0
TOP_K_SEARCH: 50      # B√∫squeda inicial
TOP_N_RERANK: 10      # Resultados finales tras reranking
```

### Sistema de Gesti√≥n de Memoria Contextual

El chatbot implementa un **sistema autom√°tico de gesti√≥n de memoria** que mantiene conversaciones largas sin perder contexto relevante:

#### Funcionamiento Autom√°tico
```python
# Monitoreo continuo del tama√±o del contexto
MAX_HISTORY_CHARS: 8000                 # L√≠mite antes de activar resumen
SLIDING_WINDOW_TURNS: 6                 # Turnos recientes siempre preservados

# Trigger autom√°tico cuando se excede el l√≠mite:
# 1. Analiza toda la conversaci√≥n
# 2. Extrae informaci√≥n cr√≠tica (nombres, fechas, decisiones, n√∫meros)
# 3. Genera resumen inteligente con LLM
# 4. Conserva √∫ltimos 6 turnos + resumen optimizado
```

#### Informaci√≥n Preservada Autom√°ticamente
- **üìÖ Fechas**: Formatos YYYY-MM-DD y DD/MM/YYYY
- **üë§ Nombres propios**: Personas, lugares, organizaciones
- **‚öñÔ∏è Decisiones**: Preferencias expresadas ("prefiero X", "decid√≠ Y")
- **‚öôÔ∏è Configuraciones**: Comandos y ajustes t√©cnicos
- **üî¢ N√∫meros importantes**: Con unidades (euros, porcentajes, medidas)
- **üêõ Problemas t√©cnicos**: Errores y sus soluciones
- **üèóÔ∏è Contexto del dominio**: Terminolog√≠a especializada

#### Ejemplo de Optimizaci√≥n
```
Conversaci√≥n original (12,000 caracteres):
[Turno 1-15: conversaci√≥n extensa sobre configuraci√≥n]

Despu√©s del resumen autom√°tico (7,500 caracteres):
[RESUMEN: Usuario configur√≥ API keys (Google, Jina), proces√≥ 3 PDFs
sobre machine learning, prefiere explicaciones t√©cnicas detalladas,
tuvo error con Qdrant que se resolvi√≥ reiniciando servicio]
[Turno 10-15: √∫ltimos 6 turnos completos preservados]
```

#### Configuraci√≥n Personalizable
```yaml
# Ajustar l√≠mites seg√∫n necesidades
MAX_HISTORY_CHARS: 12000               # Conversaciones m√°s largas
SLIDING_WINDOW_TURNS: 10               # M√°s turnos recientes
```

**‚ú® Ventajas:**
- Conversaciones ilimitadamente largas sin p√©rdida de contexto
- Preservaci√≥n inteligente de informaci√≥n cr√≠tica
- Optimizaci√≥n autom√°tica de prompts para mejor rendimiento
- Sin intervenci√≥n manual requerida

## üîß Troubleshooting

### Problemas Comunes

#### 1. Servicios no inician

**Error:** `docker compose up` falla
```bash
# Verificar logs
docker compose logs [servicio]

# Soluciones comunes
docker system prune -f              # Limpiar Docker
docker compose down -v              # Eliminar vol√∫menes
docker compose pull                 # Actualizar im√°genes
```

#### 2. Errores de API Keys

**Error:** Fallos de autenticaci√≥n o l√≠mites de API
```bash
# Verificar variables de entorno
echo $GOOGLE_API_KEY
echo $JINA_API_KEY

# Comprobar conectividad con APIs
curl -H "Authorization: Bearer $JINA_API_KEY" https://api.jina.ai/v1/embeddings

# Verificar logs de servicios
docker compose logs app | grep -i "api\|error"
```

#### 3. Ingesta falla

**Error:** PDFs no se procesan
```bash
# Verificar logs detallados
docker compose logs ingest

# Verificar PDFs
ls -la docs/                        # Comprobar archivos
file docs/*.pdf                     # Verificar formato

# Reintentar ingesta
docker compose run --rm ingest
```

#### 4. Interfaz web no carga

**Error:** http://localhost:7860 no responde
```bash
# Verificar estado de servicios
docker compose ps

# Verificar salud de app
curl -f http://localhost:8080/health

# Revisar logs
docker compose logs app

# Reiniciar servicio
docker compose restart app
```

#### 5. Errores de permisos

**Error:** Permission denied al crear carpetas
```bash
# En Linux/WSL
sudo chown -R $USER:$USER docs/
chmod -R 755 docs/

# Alternativa con Docker
docker run --rm -v $(pwd)/docs:/docs alpine chown -R 1000:1000 /docs
```

### Logs y Monitoreo

**Ver logs en tiempo real:**
```bash
# Todos los servicios
docker compose logs -f

# Servicio espec√≠fico
docker compose logs -f app

# Filtrar por nivel
docker compose logs app | grep ERROR
```

**Verificar salud de servicios:**
```bash
# Estado general
docker compose ps

# Health checks espec√≠ficos
docker inspect --format='{{.State.Health.Status}}' qdrant
docker inspect --format='{{.State.Health.Status}}' pyexec
```

### Rendimiento

**Optimizar memoria:**
```bash
# Monitorear uso de memoria
docker stats

# Limitar memoria de servicios si es necesario
docker update --memory=1g qdrant
docker update --memory=512m pyexec
```

**Optimizar velocidad:**
- Google Gemini 2.5 Flash Lite ya est√° optimizado para velocidad
- Jina embeddings v4 proporciona alta velocidad via API
- Habilitar procesamiento paralelo: `PARALLEL_RETRIEVAL=true`
- Ajustar CHUNK_SIZE seg√∫n hardware (default: 1200)
- Considerar SSD para vol√∫menes Docker
- Optimizar reranking: ajustar `TOP_K_SEARCH` y `TOP_N_RERANK`

## üìã Flujo Completo de PDF a RAG Multimodal

### Proceso de Ingesta de PDFs (ingest.py)

#### 1. üìÑ Extracci√≥n y Procesamiento de PDFs

**Extracci√≥n de texto:**
```python
# 1. Validaci√≥n autom√°tica de PDFs
- Verificaci√≥n de existencia, tama√±o (<100MB), formato v√°lido
- Carga con PyPDFLoader de LangChain
- Extracci√≥n de metadatos (t√≠tulo, autor, fecha de creaci√≥n)

# 2. Procesamiento por p√°ginas
- Asignaci√≥n de metadatos mejorados: doc_id, title, page, source
- Validaci√≥n de contenido m√≠nimo (>10 caracteres)
- Filtrado de p√°ginas vac√≠as

# 3. Chunking optimizado de texto
- RecursiveCharacterTextSplitter
- CHUNK_SIZE: 1200 caracteres
- CHUNK_OVERLAP: 180 caracteres
- Estad√≠sticas: promedio, m√≠nimo, m√°ximo chunk size
```

**Extracci√≥n multimodal de im√°genes:**
```python
# 1. Extracci√≥n con PyMuPDF (fitz)
- extract_images_from_pdf() usa PyMuPDF para extraer im√°genes embebidas
- Formatos soportados: PNG, JPEG, WebP
- Obtiene: dimensiones, bounding box, datos binarios, metadata

# 2. Preprocesamiento inteligente de im√°genes
- _normalize_image_orientation(): Corrige orientaci√≥n EXIF autom√°ticamente
- _resize_image(): Redimensiona manteniendo aspect ratio (m√°ximo 1024px lado mayor)
- _calculate_image_hash(): SHA-256 para deduplicaci√≥n robusta

# 3. Filtrado avanzado de im√°genes significativas
- Elimina im√°genes < 50x50px (demasiado peque√±as)
- Filtra aspect ratios extremos (>10:1, normalmente logos/l√≠neas)
- Descarta archivos < 500 bytes (probablemente corruptos)
- Excluye headers/footers (15% superior/inferior de p√°gina)
- Filtra baja complejidad visual (varianza de p√≠xeles)
- Deduplicaci√≥n autom√°tica por hash SHA-256
```

**Almacenamiento estructurado:**
```bash
# Estructura de directorios generada autom√°ticamente:
/var/data/rag/images/
‚îî‚îÄ‚îÄ {doc_id}/
    ‚îî‚îÄ‚îÄ p{page_number}/
        ‚îú‚îÄ‚îÄ {hash}.png          # Imagen original procesada
        ‚îî‚îÄ‚îÄ thumbs/
            ‚îî‚îÄ‚îÄ {hash}.jpg      # Thumbnail optimizado (256px max)

# Metadatos completos generados:
- image_path, thumbnail_path (rutas absolutas)
- image_uri, thumbnail_uri (rutas relativas para referencias)
- width, height, bbox (coordenadas en p√°gina)
- doc_id, page_number, image_index, hash SHA-256
```

#### 2. üßÆ Generaci√≥n de Embeddings Multimodales

**Configuraci√≥n unificada de embeddings:**
```python
# Para texto (retrieval.query - consultas de usuario)
task_config = {
    "task_type": "retrieval.query",
    "late_chunking": False,
    "normalized": True  # Para usar DOT distance en Qdrant
}

# Para documentos/im√°genes (retrieval.passage - contenido indexado)
task_config = {
    "task_type": "retrieval.passage", 
    "late_chunking": True,  # Solo para chunks de texto grandes
    "normalized": True      # Consistente con queries
}

# Modelos configurados:
- Jina: jina-embeddings-v4 (1024 dimensiones, normalizado) - CONFIGURACI√ìN ACTIVA
- Nota: El sistema est√° configurado √∫nicamente para Jina embeddings
```

**Procesamiento por lotes optimizado:**
```python
# Embeddings de texto (paralelo por chunks)
texts = [doc.page_content for doc in batch]
embeddings = emb.embed_documents(texts)  # API call a Jina

# Embeddings de im√°genes (paralelo por archivos)  
embeddings = emb.embed_images(batch_image_files)  # API call a Jina
# Procesa rutas de archivos PNG directamente
# Mismo espacio vectorial que el texto para b√∫squeda h√≠brida
```

#### 3. üóÑÔ∏è Almacenamiento en Base de Datos Vectorial (Qdrant)

**Configuraci√≥n de colecci√≥n multimodal:**
```python
# Configuraci√≥n autom√°tica seg√∫n proveedor de embeddings
MULTIMODAL_COLLECTION_CONFIG = {
    "collection_name": "rag_multimodal",
    "distance": Distance.DOT,      # Para Jina (normalizado)
    "vector_size": 1024,           # Jina embeddings-v4
}

# √çndices de payload para b√∫squeda eficiente:
- modality: keyword index ("text" | "image")
- doc_id: keyword index (agrupaci√≥n por documento)
- page_number: integer index (b√∫squeda por p√°gina)
- hash: keyword index (deduplicaci√≥n r√°pida)
- title, author: text index (b√∫squeda por metadatos)
```

**Estructura de payload unificada:**
```python
@dataclass
class MultimodalPayload:
    # Campos requeridos comunes
    id: str                    # UUID √∫nico para cada vector
    modality: Modality         # "text" | "image"
    doc_id: str               # ID del documento padre
    page_number: int          # P√°gina en el documento
    source_uri: str           # Archivo PDF original
    hash: str                 # SHA-256 para deduplicaci√≥n
    embedding_model: str      # Modelo usado (jina-embeddings-v4)
    created_at: str           # Timestamp ISO de inserci√≥n
    
    # Campos espec√≠ficos de texto
    page_content: str         # Contenido del chunk
    content_preview: str      # Primeros 200 caracteres
    
    # Campos espec√≠ficos de imagen  
    thumbnail_uri: str        # Ruta relativa del PNG
    width: int, height: int   # Dimensiones en p√≠xeles
    image_index: int          # √çndice de imagen en la p√°gina
    bbox: Dict                # Coordenadas: {"x0": float, "y0": float, "x1": float, "y1": float}
    
    # Campos opcionales comunes
    title: str                # T√≠tulo limpio del documento
    author: str               # Autor extra√≠do del PDF
    creation_date: str        # Fecha de creaci√≥n del PDF
```

**Inserci√≥n vectorial por lotes:**
```python
# Para texto: factory method optimizado
multimodal_payload = MultimodalPayload.from_text_chunk(
    page_content=text,
    doc_id=metadata['doc_id'],
    page_number=metadata['page'],
    embedding_model="jina-embeddings-v4"
)

# Para imagen: factory method con metadatos completos
multimodal_payload = MultimodalPayload.from_image_data(
    image_data=b"placeholder",  # No se almacenan datos binarios
    doc_id=doc_id,
    page_number=page_number, 
    thumbnail_uri=relative_path,
    width=800, height=600,
    embedding_model="jina-embeddings-v4"
)

# Inserci√≥n eficiente en lotes de 50 vectores
client.upsert(collection_name="rag_multimodal", points=[
    models.PointStruct(
        id=payload.id,
        vector=embedding,          # Vector 1024-dimensional
        payload=payload.to_dict()  # Metadatos completos
    )
])
```

### Proceso de Retrieval Multimodal (app.py)

#### 4. üîç Information Retrieval H√≠brido

**B√∫squeda vectorial unificada:**
```python
class CustomQdrantRetriever:
    def get_relevant_documents(self, query: str, k: int = 30):
        # 1. Generar embedding de la query del usuario
        query_embedding = self.embeddings.embed_query(query)  # Jina API
        
        # 2. B√∫squeda vectorial h√≠brida en Qdrant
        search_result = self.client.query_points(
            collection_name="rag_multimodal",
            query=query_embedding,
            limit=k,                    # B√∫squeda amplia inicial
            with_payload=True           # Incluir todos los metadatos
        )
        
        # 3. Procesar resultados por modalidad
        documents = []
        for result in search_result.points:
            payload = result.payload
            modality = payload.get('modality', 'text')
            
            if modality == 'image':
                # Crear descripci√≥n contextual para im√°genes
                thumbnail_uri = payload.get('thumbnail_uri', '')
                image_index = payload.get('image_index', 0)
                width = payload.get('width', 0)
                height = payload.get('height', 0)
                
                page_content = f"Imagen {image_index + 1} en p√°gina {payload.get('page_number', 'N/A')} (dimensiones: {width}x{height}px, thumbnail: {thumbnail_uri})"
            
            # Preservar metadatos completos + similarity score
            metadata = payload.copy()
            metadata['similarity_score'] = result.score
            
        return documents
```

**Reranking inteligente con Jina:**
```python
# Configuraci√≥n de reranking en dos etapas
RETRIEVAL_TOP_K = 30    # B√∫squeda vectorial amplia
RERANK_TOP_K = 15       # Selecci√≥n final precisa

if reranker and len(docs) > 1:
    # Aplicar reranking sem√°ntico avanzado
    reranked_docs, rerank_latency_ms = reranker.rerank_doc_objects(
        query=query,
        documents=docs,
        top_n=RERANK_TOP_K
    )
    docs = reranked_docs
    
    # Log de mejoras de relevancia
    for i, doc in enumerate(docs[:3], 1):
        rerank_score = doc.metadata.get('rerank_score', 'N/A')
        title = doc.metadata.get('title', 'Unknown')[:50]
        logger.debug(f"Reranked doc {i}: {title} (score: {rerank_score})")
```

#### 5. üß† Generaci√≥n RAG Multimodal con Gemini

**Construcci√≥n de contexto h√≠brido:**
```python
# Contexto diferenciado por modalidad
context_parts = []
image_documents = []  # Tracking para procesamiento multimodal

for i, doc in enumerate(docs):
    doc_title = doc.metadata.get('title', 'Documento desconocido')
    page_num = doc.metadata.get('page_number', 'N/A')
    modality = doc.metadata.get('modality', 'text')
    
    if modality == 'image':
        # Contexto enriquecido para im√°genes
        thumbnail_uri = doc.metadata.get('thumbnail_uri', '')
        image_index = doc.metadata.get('image_index', 0)
        width = doc.metadata.get('width', 0)
        height = doc.metadata.get('height', 0)
        
        context_part = f"""DOCUMENTO {i+1}: {doc_title}
P√ÅGINA: {page_num}
TIPO: IMAGEN {image_index + 1}
DIMENSIONES: {width}x{height}px
UBICACI√ìN: {thumbnail_uri}
FUENTE: {doc.metadata.get('source_uri', '')}
CONTENIDO: {doc.page_content}
---"""
        
        # Guardar para procesamiento visual
        image_documents.append({
            'doc_index': i + 1,
            'thumbnail_uri': thumbnail_uri,  # Ruta del PNG original
            'title': doc_title,
            'page': page_num,
            'image_index': image_index
        })
    else:
        # Contexto est√°ndar para texto
        context_part = f"""DOCUMENTO {i+1}: {doc_title}
P√ÅGINA: {page_num}
CONTENIDO:
{doc.page_content}
---"""
    
    context_parts.append(context_part)

context = "\n\n".join(context_parts)
```

**Procesamiento visual con Gemini 2.5 Flash Lite:**
```python
if image_documents:  # Hay im√°genes relevantes
    logger.info(f"Preparando RAG multimodal con {len(image_documents)} im√°genes")
    
    message_content = []
    
    # 1. Prompt textual con contexto h√≠brido
    text_prompt = f"""{sistema_prompt}

Contexto:
{context}

Historial:
{historial_formateado}

Pregunta: {query}

Por favor analiza tanto el texto como las im√°genes proporcionadas. Si las im√°genes contienen gr√°ficos, tablas o diagramas relevantes, descr√≠belos y √∫salos en tu respuesta.

Respuesta:"""
    
    message_content.append({
        "type": "text",
        "text": text_prompt
    })
    
    # 2. Cargar y agregar im√°genes (limitado a 5 m√°s relevantes)
    images_added = 0
    max_images = 5
    
    for img_doc in image_documents[:max_images]:
        # Cargar imagen desde almacenamiento
        image_path = img_doc['thumbnail_uri']  # PNG original (no thumbnail)
        image_base64 = load_image_as_base64(image_path)
        
        if image_base64:  # data:image/png;base64,iVBORw0KGgoAAAANSUhEU...
            message_content.append({
                "type": "image_url", 
                "image_url": image_base64
            })
            images_added += 1
            logger.info(f"Added image {images_added}: Doc {img_doc['doc_index']}, Page {img_doc['page']}")
    
    # 3. Invocar Gemini con contenido multimodal
    human_message = HumanMessage(content=message_content)
    resp = current_llm.invoke([human_message]).content.strip()
```

**Sistema de citas inline:**
```python
# 1. Extracci√≥n autom√°tica de documentos citados
cited_doc_numbers = extract_cited_documents(response)  
# Busca patrones: "DOCUMENTO 1", "DOCUMENTO 7"

# 2. Mapeo secuencial para legibilidad
citation_mapping = create_citation_mapping(cited_doc_numbers)  
# {1: 1, 7: 2} - doc original -> n√∫mero secuencial

# 3. Reescritura con formato inline  
processed_response = rewrite_document_references(response, citation_mapping)
# "DOCUMENTO 1" ‚Üí "[1]", "DOCUMENTO 7" ‚Üí "[2]"

# 4. Generaci√≥n de referencias completas
citations_text = generate_citations_for_cited_docs(docs, cited_doc_numbers, citation_mapping)

# Formato final multimodal:
"""
Respuesta con citas [1] y [2] basada en el an√°lisis de texto e im√°genes.

üìö Fuentes consultadas:
[1] Manual de Usuario (p√°g. 5)
[2] Imagen 2 en Configuraci√≥n Avanzada (p√°g. 12) - 800x600px - thumbnail: config/p12/a1b2c3d4.png
"""
```

### Flujo Completo Integrado

```
üìÑ PDF Input ‚Üí üîß Extract ‚Üí üñºÔ∏è Process ‚Üí üßÆ Embed ‚Üí üóÑÔ∏è Store ‚Üí üîç Retrieve ‚Üí üß† Generate

1. PDF Files (docs/)
   ‚Üì
2. ingest.py
   ‚îú‚îÄ PyPDFLoader (extracci√≥n de texto por p√°ginas)
   ‚îú‚îÄ PyMuPDF (extracci√≥n de im√°genes embebidas)  
   ‚îú‚îÄ Validaci√≥n + Filtrado inteligente
   ‚îú‚îÄ Chunking optimizado (1200/180 caracteres)
   ‚îî‚îÄ Almacenamiento estructurado (/var/data/rag/images/)
   ‚Üì
3. embedding_factory.py  
   ‚îú‚îÄ Jina API embeddings-v4 (texto + im√°genes)
   ‚îú‚îÄ Configuraci√≥n: task_type retrieval.passage/query
   ‚îú‚îÄ Normalizaci√≥n: True (DOT distance compatible)
   ‚îî‚îÄ Procesamiento por lotes optimizado
   ‚Üì
4. Qdrant Vector Database
   ‚îú‚îÄ Colecci√≥n multimodal unificada (rag_multimodal)
   ‚îú‚îÄ Payload estructurado: MultimodalPayload
   ‚îú‚îÄ √çndices optimizados: modality, doc_id, page_number  
   ‚îî‚îÄ Deduplicaci√≥n SHA-256 autom√°tica
   ‚Üì
5. User Query ‚Üí app.py
   ‚Üì
6. CustomQdrantRetriever
   ‚îú‚îÄ embed_query(user_input) con Jina
   ‚îú‚îÄ query_points(qdrant) b√∫squeda h√≠brida
   ‚îú‚îÄ Jina Reranker (30‚Üí15 documentos)
   ‚îî‚îÄ Contexto multimodal estructurado
   ‚Üì
7. Google Gemini 2.5 Flash Lite
   ‚îú‚îÄ Prompt textual + Im√°genes base64
   ‚îú‚îÄ Sistema prompt especializado multimodal
   ‚îú‚îÄ Procesamiento visual nativo
   ‚îî‚îÄ Generaci√≥n de citas DOCUMENTO N
   ‚Üì
8. Post-processing
   ‚îú‚îÄ Extracci√≥n de documentos citados
   ‚îú‚îÄ Mapeo secuencial de citas
   ‚îú‚îÄ Reescritura inline [N]
   ‚îî‚îÄ Referencias completas multimodales
   ‚Üì
9. Final Response
   ‚îú‚îÄ Contenido h√≠brido (texto + visual)
   ‚îú‚îÄ Citas inline [1], [2], [3]
   ‚îî‚îÄ Referencias: üìö Fuentes consultadas con metadatos completos
```

Esta arquitectura permite un RAG verdaderamente multimodal donde:
- ‚úÖ **PDFs se procesan completamente** (texto + todas las im√°genes)
- ‚úÖ **B√∫squedas h√≠bridas** encuentran contenido relevante independiente de modalidad
- ‚úÖ **Respuestas enriquecidas** que combinan informaci√≥n textual y visual
- ‚úÖ **Citas precisas** que referencian tanto texto como im√°genes espec√≠ficas
- ‚úÖ **Escalabilidad** atrav√©s de APIs (Jina + Google) sin procesamiento local pesado

## üß™ Testing

```bash
# Ejecutar tests completos
python run_tests.py

# Tests espec√≠ficos
pytest tests/unit/                     # Tests unitarios
pytest tests/integration/              # Tests de integraci√≥n
pytest tests/e2e/                      # Tests end-to-end

# Test de aceptaci√≥n
python validate_acceptance_criteria.py
```

## üìä Monitoreo y M√©tricas

**Endpoints de salud:**
- App: http://localhost:8080/health
- Qdrant: http://localhost:6333/healthz
- PyExec: http://localhost:8001/health

**M√©tricas disponibles:**
- Qdrant: Dashboard en http://localhost:6333/dashboard
- Docker: `docker compose top` y `docker stats`

## üöÄ Despliegue en Producci√≥n

### Consideraciones de Seguridad

1. **Cambiar puertos por defecto:**
   ```yaml
   ports:
     - "7861:7860"  # En lugar de 7860:7860
   ```

2. **Variables de entorno sensibles:**
   ```bash
   # Crear .env file
   echo "GRADIO_AUTH=admin:password" > .env
   ```

3. **Firewall y reverse proxy:**
   ```bash
   # Solo exponer puertos necesarios
   # Usar nginx/traefik como proxy
   ```

### Escalabilidad

```yaml
# En docker-compose.yml
deploy:
  replicas: 2
  resources:
    limits:
      memory: 2G
    reservations:
      memory: 1G
```

## ü§ù Desarrollo y Contribuci√≥n

**Estructura del proyecto:**
```
‚îú‚îÄ‚îÄ app.py              # Aplicaci√≥n principal Gradio
‚îú‚îÄ‚îÄ ingest.py           # Procesamiento de PDFs
‚îú‚îÄ‚îÄ pyexec_service.py   # Servicio de ejecuci√≥n Python
‚îú‚îÄ‚îÄ docker-compose.yml  # Configuraci√≥n de servicios
‚îú‚îÄ‚îÄ Dockerfile          # Imagen multi-etapa
‚îú‚îÄ‚îÄ requirements.*.txt  # Dependencias por servicio
‚îú‚îÄ‚îÄ tests/              # Suite de testing
‚îî‚îÄ‚îÄ docs/               # Documentos para ingestar
```

**Flujo de desarrollo:**
1. Fork del repositorio
2. Crear rama feature/nombre-feature
3. Desarrollar con tests
4. Ejecutar suite completa: `python run_tests.py`
5. Crear Pull Request

**Est√°ndares de c√≥digo:**
- Python: Black, isort, flake8
- Dockerfiles: Hadolint
- Documentaci√≥n: Markdown lint

## üìÑ Licencia

[Especificar licencia del proyecto]

## üÜò Soporte

- **Issues:** [GitHub Issues](link-to-issues)
- **Documentaci√≥n:** [Wiki](link-to-wiki)
- **Chat:** [Discord/Slack](link-to-chat)

---

**√öltima actualizaci√≥n:** Agosto 2025 (multimodal RAG con Jina embeddings y reranking)
**Versi√≥n:** 2.0.0
