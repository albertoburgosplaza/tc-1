
# Chatbot RAG con Google Gemini ‚Äî Microservicios con Docker Compose

Sistema de chatbot con Retrieval Augmented Generation (RAG) que permite consultar documentos PDF y ejecutar c√≥digo Python de forma segura. Utiliza Google Gemini como modelo de lenguaje y una arquitectura de microservicios con Docker Compose para facilitar el despliegue y escalabilidad.

## üèóÔ∏è Arquitectura

**Servicios principales:**
- **qdrant**: Base de datos vectorial para almacenamiento de embeddings
- **pyexec**: Microservicio para ejecutar expresiones Python de forma segura
- **app**: Interfaz web con Gradio + LangChain + Google Gemini que orquesta RAG
- **ingest**: Job de procesamiento para ingestar PDFs en Qdrant con embeddings de Google

## ‚ö° Inicio R√°pido

### Requisitos del Sistema

**Obligatorios:**
- Docker (versi√≥n 20.10 o superior)
- Docker Compose (versi√≥n 2.0 o superior)
- **Google API Key** (para acceso a Gemini)
- M√≠nimo 2GB RAM disponible
- Al menos 2GB de espacio en disco

**Verificar instalaci√≥n:**
```bash
docker --version && docker compose version
```

### Instalaci√≥n Autom√°tica

Para un setup completo en menos de 5 minutos:

1. **Configurar API Key:**
   ```bash
   export GOOGLE_API_KEY="tu_api_key_aqui"
   ```

2. **Clonar y preparar:**
   ```bash
   git clone <repository-url>
   cd turingchallenge-reto-1
   chmod +x setup.sh
   ./setup.sh
   ```

### Instalaci√≥n Manual

#### 1. Preparar Documentos

Crear carpeta de documentos y a√±adir PDFs:
```bash
# Crear carpeta
mkdir -p docs

# A√±adir tus PDFs (ejemplos)
cp /ruta/a/tus/*.pdf docs/
# O descargar documentos de ejemplo
wget -P docs/ "https://example.com/sample.pdf"
```

**Limitaciones:**
- Tama√±o m√°ximo por PDF: 100MB
- Formatos soportados: PDF √∫nicamente
- M√≠nimo contenido por documento: 10 caracteres

#### 2. Configurar Google API Key

```bash
# Configurar variable de entorno
export GOOGLE_API_KEY="tu_google_api_key_aqui"

# O crear archivo .env
echo "GOOGLE_API_KEY=tu_google_api_key_aqui" > .env
```

**C√≥mo obtener Google API Key:**
1. Ir a [Google AI Studio](https://makersuite.google.com/app/apikey)
2. Crear una nueva API key
3. Habilitar Generative AI API

#### 3. Levantar Servicios

```bash
# Construir y levantar servicios
docker compose up -d --build qdrant pyexec app

# Verificar que los servicios est√°n saludables
docker compose ps
```

**Tiempo estimado:** 3-5 minutos (primera vez)

#### 4. Procesar Documentos

```bash
# Ejecutar ingesta de PDFs
docker compose run --rm ingest

# Verificar ingesta exitosa
docker logs ingest
```

**Tiempo estimado:** 1-5 minutos (seg√∫n cantidad de PDFs)

#### 5. Acceder a la Interfaz

- **Interfaz principal:** http://localhost:7860
- **API health check:** http://localhost:8080/health
- **Qdrant dashboard:** http://localhost:6333/dashboard

## üéØ Gu√≠a de Uso

### Consultas RAG (Documentos)

**Ejemplos de preguntas:**
```
- "¬øQu√© dice el documento sobre inteligencia artificial?"
- "Resume los puntos principales del cap√≠tulo 3"
- "¬øCu√°les son las conclusiones del estudio?"
- "Compara las ventajas de Random Forest vs Redes Neuronales"
```

**Caracter√≠sticas:**
- Respuestas incluyen citas con documento y p√°gina
- B√∫squeda sem√°ntica en el contenido
- Soporte para consultas en m√∫ltiples idiomas
- An√°lisis comparativo entre documentos

### Ejecuci√≥n de C√≥digo Python

**Sintaxis soportada:**
```python
# Operaciones matem√°ticas
python: (2+3)*10
python: import math; math.sqrt(16)

# An√°lisis estad√≠stico
python: import statistics; statistics.mean([1,2,3,4,5])

# An√°lisis de datos
python: [1,2,3,4,5]; sum(_)/len(_)

# Consultas en lenguaje natural
"Calcula la media de 1, 5, 10"
"¬øCu√°nto es 15% de 200?"
"Calcula el inter√©s compuesto de $5000 al 3.5% por 7 a√±os"
```

**Limitaciones de seguridad:**
- Timeout: 5 segundos
- M√°ximo 500 caracteres por expresi√≥n
- Sin acceso a archivos del sistema
- Bibliotecas limitadas (math, statistics, b√°sicas)

### Consultas Mixtas

Puedes combinar ambas funcionalidades:
```
"Seg√∫n el documento financiero, calcula el ROI si la inversi√≥n es de $100,000 y los ingresos son python: 150000 * 1.2"

"El paper menciona una muestra de 200 participantes. ¬øEs estad√≠sticamente significativo con un margen de error del 3.5%? python: 1.96/0.035**2 * 0.25"
```

### Ejemplos Completos

Para ejemplos detallados con respuestas esperadas, consulta **[EXAMPLES.md](EXAMPLES.md)** que incluye:
- üìä Casos de an√°lisis financiero con c√°lculos
- üî¨ Validaci√≥n de datos de investigaci√≥n
- üí¨ Conversaciones multi-turno con memoria contextual
- üßÆ An√°lisis estad√≠stico de datasets
- ‚ö†Ô∏è Manejo de errores y casos l√≠mite

## ‚öôÔ∏è Configuraci√≥n Avanzada

### Variables de Entorno Principales

#### Servicio App
```yaml
# Configuraci√≥n del LLM (solo Google Gemini)
LLM_PROVIDER: google                     # √önico proveedor soportado
GOOGLE_API_KEY: "${GOOGLE_API_KEY}"      # API Key de Google AI (REQUERIDA)

# Configuraci√≥n de Qdrant
QDRANT_URL: http://qdrant:6333           # URL interna de Qdrant
COLLECTION_NAME: corpus_pdf              # Nombre de la colecci√≥n vectorial

# Configuraci√≥n de la interfaz
GRADIO_SERVER_NAME: 0.0.0.0             # Host de Gradio
GRADIO_SERVER_PORT: 7860                 # Puerto de Gradio

# Validaci√≥n de entrada
MAX_HISTORY_CHARS: 8000                  # M√°ximo caracteres en historial
MAX_QUERY_LENGTH: 2000                   # M√°ximo caracteres por consulta
MIN_QUERY_LENGTH: 1                      # M√≠nimo caracteres por consulta

# Integraci√≥n Python
PYEXEC_URL: http://pyexec:8001           # URL del servicio Python
```

#### Servicio PyExec
```yaml
PYEXEC_TIMEOUT_SEC: 5                    # Timeout para ejecuci√≥n Python
MAX_EXPR_LENGTH: 500                     # M√°ximo caracteres en expresi√≥n
MAX_EXPR_COMPLEXITY: 100                 # L√≠mite de complejidad AST
```

#### Servicio Ingest
```yaml
# Configuraci√≥n de embeddings (Google)
EMBEDDING_MODEL: models/embedding-001    # Modelo de Google para embeddings
EMBEDDING_PROVIDER: google              # Proveedor de embeddings
DOCUMENTS_DIR: /app/docs                # Carpeta interna de documentos

# Procesamiento de PDFs
MAX_PDF_SIZE_MB: 100                     # Tama√±o m√°ximo por PDF
CHUNK_SIZE: 1200                         # Tama√±o de chunks en caracteres
CHUNK_OVERLAP: 180                       # Solapamiento entre chunks
MIN_CONTENT_LENGTH: 10                   # Contenido m√≠nimo por chunk
```

### Modelo LLM Configurado

Este sistema utiliza √∫nicamente **Google Gemini 2.5 Flash Lite** como modelo de lenguaje:

**Caracter√≠sticas:**
- ‚ö° **Ultra velocidad:** Respuestas en milisegundos
- üåê **API-based:** Sin modelos locales, menor uso de recursos
- üîß **Pre-configurado:** Listo para usar con tu Google API Key
- üåç **Multileng√ºe:** Soporte nativo para m√∫ltiples idiomas

**Configuraci√≥n requerida:**
```bash
# Solo necesitas tu Google API Key
export GOOGLE_API_KEY="tu_api_key_aqui"
```

### Modelo de Embeddings Configurado

El sistema utiliza **Google `models/embedding-001`** para generar embeddings:

**Caracter√≠sticas:**
- üìä **Alta calidad:** 768 dimensiones optimizadas para RAG
- üöÄ **R√°pido:** Generaci√≥n via API sin procesamiento local
- üîÑ **Consistente:** Embeddings estables entre sesiones

**Configuraci√≥n actual:**
   ```yaml
   # En docker-compose.yml servicio ingest
   EMBEDDING_MODEL: sentence-transformers/all-mpnet-base-v2
   ```

2. **Actualizar dimensiones en c√≥digo:**
   ```python
   # En ingest.py, ajustar:
   # all-MiniLM-L6-v2: 384 dimensiones
   # all-mpnet-base-v2: 768 dimensiones
   ```

3. **Limpiar y re-ingestar:**
   ```bash
   docker compose down -v  # Elimina vol√∫menes
   docker compose up -d qdrant
   docker compose run --rm ingest
   ```

## üîß Troubleshooting

### Problemas Comunes

#### 1. Servicios no inician

**Error:** `docker compose up` falla
```bash
# Verificar logs
docker compose logs [servicio]

# Soluciones comunes
docker system prune -f              # Limpiar Docker
docker compose down -v              # Eliminar vol√∫menes
docker compose pull                 # Actualizar im√°genes
```

#### 2. Modelo no descarga

**Error:** `ollama pull` falla o es muy lento
```bash
# Verificar espacio en disco
df -h

# El modelo configurado por defecto ya es muy ligero
docker exec -it ollama ollama pull llama3.2:1b

# Verificar conectividad
docker exec -it ollama curl -I https://ollama.ai
```

#### 3. Ingesta falla

**Error:** PDFs no se procesan
```bash
# Verificar logs detallados
docker compose logs ingest

# Verificar PDFs
ls -la docs/                        # Comprobar archivos
file docs/*.pdf                     # Verificar formato

# Reintentar ingesta
docker compose run --rm ingest
```

#### 4. Interfaz web no carga

**Error:** http://localhost:7860 no responde
```bash
# Verificar estado de servicios
docker compose ps

# Verificar salud de app
curl -f http://localhost:8080/health

# Revisar logs
docker compose logs app

# Reiniciar servicio
docker compose restart app
```

#### 5. Errores de permisos

**Error:** Permission denied al crear carpetas
```bash
# En Linux/WSL
sudo chown -R $USER:$USER docs/
chmod -R 755 docs/

# Alternativa con Docker
docker run --rm -v $(pwd)/docs:/docs alpine chown -R 1000:1000 /docs
```

### Logs y Monitoreo

**Ver logs en tiempo real:**
```bash
# Todos los servicios
docker compose logs -f

# Servicio espec√≠fico
docker compose logs -f app

# Filtrar por nivel
docker compose logs app | grep ERROR
```

**Verificar salud de servicios:**
```bash
# Estado general
docker compose ps

# Health checks espec√≠ficos
docker inspect --format='{{.State.Health.Status}}' qdrant
docker inspect --format='{{.State.Health.Status}}' ollama
```

### Rendimiento

**Optimizar memoria:**
```bash
# Limitar memoria de Ollama
docker update --memory=2g ollama

# Monitorear uso
docker stats
```

**Optimizar velocidad:**
- llama3.2:1b ya est√° optimizado para velocidad por defecto
- Para m√°s potencia: cambiar a mistral:7b-instruct
- Ajustar CHUNK_SIZE seg√∫n hardware (default: 1200)
- Considerar SSD para vol√∫menes Docker

## üß™ Testing

```bash
# Ejecutar tests completos
python run_tests.py

# Tests espec√≠ficos
pytest tests/unit/                     # Tests unitarios
pytest tests/integration/              # Tests de integraci√≥n
pytest tests/e2e/                      # Tests end-to-end

# Test de aceptaci√≥n
python validate_acceptance_criteria.py
```

## üìä Monitoreo y M√©tricas

**Endpoints de salud:**
- App: http://localhost:8080/health
- Qdrant: http://localhost:6333/healthz
- Ollama: http://localhost:11434/api/tags
- PyExec: http://localhost:8001/health

**M√©tricas disponibles:**
- Qdrant: Dashboard en http://localhost:6333/dashboard
- Docker: `docker compose top` y `docker stats`

## üöÄ Despliegue en Producci√≥n

### Consideraciones de Seguridad

1. **Cambiar puertos por defecto:**
   ```yaml
   ports:
     - "7861:7860"  # En lugar de 7860:7860
   ```

2. **Variables de entorno sensibles:**
   ```bash
   # Crear .env file
   echo "GRADIO_AUTH=admin:password" > .env
   ```

3. **Firewall y reverse proxy:**
   ```bash
   # Solo exponer puertos necesarios
   # Usar nginx/traefik como proxy
   ```

### Escalabilidad

```yaml
# En docker-compose.yml
deploy:
  replicas: 2
  resources:
    limits:
      memory: 2G
    reservations:
      memory: 1G
```

## ü§ù Desarrollo y Contribuci√≥n

**Estructura del proyecto:**
```
‚îú‚îÄ‚îÄ app.py              # Aplicaci√≥n principal Gradio
‚îú‚îÄ‚îÄ ingest.py           # Procesamiento de PDFs
‚îú‚îÄ‚îÄ pyexec_service.py   # Servicio de ejecuci√≥n Python
‚îú‚îÄ‚îÄ docker-compose.yml  # Configuraci√≥n de servicios
‚îú‚îÄ‚îÄ Dockerfile          # Imagen multi-etapa
‚îú‚îÄ‚îÄ requirements.*.txt  # Dependencias por servicio
‚îú‚îÄ‚îÄ tests/              # Suite de testing
‚îî‚îÄ‚îÄ docs/              # Documentos para ingestar
```

**Flujo de desarrollo:**
1. Fork del repositorio
2. Crear rama feature/nombre-feature
3. Desarrollar con tests
4. Ejecutar suite completa: `python run_tests.py`
5. Crear Pull Request

**Est√°ndares de c√≥digo:**
- Python: Black, isort, flake8
- Dockerfiles: Hadolint
- Documentaci√≥n: Markdown lint

## üìÑ Licencia

[Especificar licencia del proyecto]

## üÜò Soporte

- **Issues:** [GitHub Issues](link-to-issues)
- **Documentaci√≥n:** [Wiki](link-to-wiki)
- **Chat:** [Discord/Slack](link-to-chat)

---

**√öltima actualizaci√≥n:** Agosto 2024 (actualizado modelo llama3.2:1b)
**Versi√≥n:** 1.0.0
