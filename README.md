
# Chatbot RAG con Google Gemini â€” Microservicios con Docker Compose

Sistema de chatbot con Retrieval Augmented Generation (RAG) que permite consultar documentos PDF y ejecutar cÃ³digo Python de forma segura. Utiliza Google Gemini como modelo de lenguaje y una arquitectura de microservicios con Docker Compose para facilitar el despliegue y escalabilidad.

## ğŸ—ï¸ Arquitectura

**Servicios principales:**
- **qdrant**: Base de datos vectorial para almacenamiento de embeddings
- **pyexec**: Microservicio para ejecutar expresiones Python de forma segura
- **app**: Interfaz web con Gradio + LangChain + Google Gemini que orquesta RAG
- **ingest**: Job de procesamiento para ingestar PDFs en Qdrant con embeddings de Google

## âš¡ Inicio RÃ¡pido

### Requisitos del Sistema

**Obligatorios:**
- Docker (versiÃ³n 20.10 o superior)
- Docker Compose (versiÃ³n 2.0 o superior)
- **Google API Key** (para acceso a Gemini)
- MÃ­nimo 2GB RAM disponible
- Al menos 2GB de espacio en disco

**Verificar instalaciÃ³n:**
```bash
docker --version && docker compose version
```

### InstalaciÃ³n AutomÃ¡tica

Para un setup completo en menos de 5 minutos:

1. **Configurar API Key:**
   ```bash
   export GOOGLE_API_KEY="tu_api_key_aqui"
   ```

2. **Clonar y preparar:**
   ```bash
   git clone <repository-url>
   cd turingchallenge-reto-1
   chmod +x setup.sh
   ./setup.sh
   ```

### InstalaciÃ³n Manual

#### 1. Preparar Documentos

Crear carpeta de documentos y aÃ±adir PDFs:
```bash
# Crear carpeta
mkdir -p docs

# AÃ±adir tus PDFs (ejemplos)
cp /ruta/a/tus/*.pdf docs/
# O descargar documentos de ejemplo
wget -P docs/ "https://example.com/sample.pdf"
```

**Limitaciones:**
- TamaÃ±o mÃ¡ximo por PDF: 100MB
- Formatos soportados: PDF Ãºnicamente
- MÃ­nimo contenido por documento: 10 caracteres

#### 2. Configurar Google API Key

```bash
# Configurar variable de entorno
export GOOGLE_API_KEY="tu_google_api_key_aqui"

# O crear archivo .env
echo "GOOGLE_API_KEY=tu_google_api_key_aqui" > .env
```

**CÃ³mo obtener Google API Key:**
1. Ir a [Google AI Studio](https://makersuite.google.com/app/apikey)
2. Crear una nueva API key
3. Habilitar Generative AI API

#### 3. Levantar Servicios

```bash
# Construir y levantar servicios
docker compose up -d --build qdrant pyexec app

# Verificar que los servicios estÃ¡n saludables
docker compose ps
```

**Tiempo estimado:** 3-5 minutos (primera vez)

#### 4. Procesar Documentos

```bash
# Ejecutar ingesta de PDFs
docker compose run --rm ingest

# Verificar ingesta exitosa
docker logs ingest
```

**Tiempo estimado:** 1-5 minutos (segÃºn cantidad de PDFs)

#### 5. Acceder a la Interfaz

- **Interfaz principal:** http://localhost:7860
- **API health check:** http://localhost:8080/health
- **Qdrant dashboard:** http://localhost:6333/dashboard

## ğŸ¯ GuÃ­a de Uso

### Consultas RAG (Documentos)

**Ejemplos de preguntas:**
```
- "Â¿QuÃ© dice el documento sobre inteligencia artificial?"
- "Resume los puntos principales del capÃ­tulo 3"
- "Â¿CuÃ¡les son las conclusiones del estudio?"
- "Compara las ventajas de Random Forest vs Redes Neuronales"
```

**CaracterÃ­sticas:**
- Respuestas incluyen citas con documento y pÃ¡gina
- BÃºsqueda semÃ¡ntica en el contenido
- Soporte para consultas en mÃºltiples idiomas
- AnÃ¡lisis comparativo entre documentos

### EjecuciÃ³n de CÃ³digo Python

**Sintaxis soportada:**
```python
# Operaciones matemÃ¡ticas
python: (2+3)*10
python: import math; math.sqrt(16)

# AnÃ¡lisis estadÃ­stico
python: import statistics; statistics.mean([1,2,3,4,5])

# AnÃ¡lisis de datos
python: [1,2,3,4,5]; sum(_)/len(_)

# Consultas en lenguaje natural
"Calcula la media de 1, 5, 10"
"Â¿CuÃ¡nto es 15% de 200?"
"Calcula el interÃ©s compuesto de $5000 al 3.5% por 7 aÃ±os"
```

**Limitaciones de seguridad:**
- Timeout: 5 segundos
- MÃ¡ximo 500 caracteres por expresiÃ³n
- Sin acceso a archivos del sistema
- Bibliotecas limitadas (math, statistics, bÃ¡sicas)

### Consultas Mixtas

Puedes combinar ambas funcionalidades:
```
"SegÃºn el documento financiero, calcula el ROI si la inversiÃ³n es de $100,000 y los ingresos son python: 150000 * 1.2"

"El paper menciona una muestra de 200 participantes. Â¿Es estadÃ­sticamente significativo con un margen de error del 3.5%? python: 1.96/0.035**2 * 0.25"
```

### Ejemplos Completos

Para ejemplos detallados con respuestas esperadas, consulta **[EXAMPLES.md](EXAMPLES.md)** que incluye:
- ğŸ“Š Casos de anÃ¡lisis financiero con cÃ¡lculos
- ğŸ”¬ ValidaciÃ³n de datos de investigaciÃ³n
- ğŸ’¬ Conversaciones multi-turno con memoria contextual
- ğŸ§® AnÃ¡lisis estadÃ­stico de datasets
- âš ï¸ Manejo de errores y casos lÃ­mite

## âš™ï¸ ConfiguraciÃ³n Avanzada

### Variables de Entorno Principales

#### Servicio App
```yaml
# ConfiguraciÃ³n del LLM (solo Google Gemini)
LLM_PROVIDER: google                     # Ãšnico proveedor soportado
GOOGLE_API_KEY: "${GOOGLE_API_KEY}"      # API Key de Google AI (REQUERIDA)

# ConfiguraciÃ³n de Qdrant
QDRANT_URL: http://qdrant:6333           # URL interna de Qdrant
COLLECTION_NAME: corpus_pdf              # Nombre de la colecciÃ³n vectorial

# ConfiguraciÃ³n de la interfaz
GRADIO_SERVER_NAME: 0.0.0.0             # Host de Gradio
GRADIO_SERVER_PORT: 7860                 # Puerto de Gradio

# ValidaciÃ³n de entrada
MAX_HISTORY_CHARS: 8000                  # MÃ¡ximo caracteres en historial
MAX_QUERY_LENGTH: 2000                   # MÃ¡ximo caracteres por consulta
MIN_QUERY_LENGTH: 1                      # MÃ­nimo caracteres por consulta

# IntegraciÃ³n Python
PYEXEC_URL: http://pyexec:8001           # URL del servicio Python
```

#### Servicio PyExec
```yaml
PYEXEC_TIMEOUT_SEC: 5                    # Timeout para ejecuciÃ³n Python
MAX_EXPR_LENGTH: 500                     # MÃ¡ximo caracteres en expresiÃ³n
MAX_EXPR_COMPLEXITY: 100                 # LÃ­mite de complejidad AST
```

#### Servicio Ingest
```yaml
# ConfiguraciÃ³n de embeddings (Google)
EMBEDDING_MODEL: models/embedding-001    # Modelo de Google para embeddings
EMBEDDING_PROVIDER: google              # Proveedor de embeddings
DOCUMENTS_DIR: /app/docs                # Carpeta interna de documentos

# Procesamiento de PDFs
MAX_PDF_SIZE_MB: 100                     # TamaÃ±o mÃ¡ximo por PDF
CHUNK_SIZE: 1200                         # TamaÃ±o de chunks en caracteres
CHUNK_OVERLAP: 180                       # Solapamiento entre chunks
MIN_CONTENT_LENGTH: 10                   # Contenido mÃ­nimo por chunk
```

### Modelo LLM Configurado

Este sistema utiliza Ãºnicamente **Google Gemini 2.5 Flash Lite** como modelo de lenguaje:

**CaracterÃ­sticas:**
- âš¡ **Ultra velocidad:** Respuestas en milisegundos
- ğŸŒ **API-based:** Sin modelos locales, menor uso de recursos
- ğŸ”§ **Pre-configurado:** Listo para usar con tu Google API Key
- ğŸŒ **MultilengÃ¼e:** Soporte nativo para mÃºltiples idiomas

**ConfiguraciÃ³n requerida:**
```bash
# Solo necesitas tu Google API Key
export GOOGLE_API_KEY="tu_api_key_aqui"
```

### Modelo de Embeddings Configurado

El sistema utiliza **Google `models/embedding-001`** para generar embeddings:

**CaracterÃ­sticas:**
- ğŸ“Š **Alta calidad:** 768 dimensiones optimizadas para RAG
- ğŸš€ **RÃ¡pido:** GeneraciÃ³n via API sin procesamiento local
- ğŸ”„ **Consistente:** Embeddings estables entre sesiones

**ConfiguraciÃ³n actual:**
   ```yaml
   # En docker-compose.yml servicio ingest
   EMBEDDING_MODEL: sentence-transformers/all-mpnet-base-v2
   ```

2. **Actualizar dimensiones en cÃ³digo:**
   ```python
   # En ingest.py, ajustar:
   # all-MiniLM-L6-v2: 384 dimensiones
   # all-mpnet-base-v2: 768 dimensiones
   ```

3. **Limpiar y re-ingestar:**
   ```bash
   docker compose down -v  # Elimina volÃºmenes
   docker compose up -d qdrant
   docker compose run --rm ingest
   ```

## ğŸ”§ Troubleshooting

### Problemas Comunes

#### 1. Servicios no inician

**Error:** `docker compose up` falla
```bash
# Verificar logs
docker compose logs [servicio]

# Soluciones comunes
docker system prune -f              # Limpiar Docker
docker compose down -v              # Eliminar volÃºmenes
docker compose pull                 # Actualizar imÃ¡genes
```

#### 2. Modelo no descarga

**Error:** `ollama pull` falla o es muy lento
```bash
# Verificar espacio en disco
df -h

# El modelo configurado por defecto ya es muy ligero
docker exec -it ollama ollama pull llama3.2:1b

# Verificar conectividad
docker exec -it ollama curl -I https://ollama.ai
```

#### 3. Ingesta falla

**Error:** PDFs no se procesan
```bash
# Verificar logs detallados
docker compose logs ingest

# Verificar PDFs
ls -la docs/                        # Comprobar archivos
file docs/*.pdf                     # Verificar formato

# Reintentar ingesta
docker compose run --rm ingest
```

#### 4. Interfaz web no carga

**Error:** http://localhost:7860 no responde
```bash
# Verificar estado de servicios
docker compose ps

# Verificar salud de app
curl -f http://localhost:8080/health

# Revisar logs
docker compose logs app

# Reiniciar servicio
docker compose restart app
```

#### 5. Errores de permisos

**Error:** Permission denied al crear carpetas
```bash
# En Linux/WSL
sudo chown -R $USER:$USER docs/
chmod -R 755 docs/

# Alternativa con Docker
docker run --rm -v $(pwd)/docs:/docs alpine chown -R 1000:1000 /docs
```

### Logs y Monitoreo

**Ver logs en tiempo real:**
```bash
# Todos los servicios
docker compose logs -f

# Servicio especÃ­fico
docker compose logs -f app

# Filtrar por nivel
docker compose logs app | grep ERROR
```

**Verificar salud de servicios:**
```bash
# Estado general
docker compose ps

# Health checks especÃ­ficos
docker inspect --format='{{.State.Health.Status}}' qdrant
docker inspect --format='{{.State.Health.Status}}' ollama
```

### Rendimiento

**Optimizar memoria:**
```bash
# Limitar memoria de Ollama
docker update --memory=2g ollama

# Monitorear uso
docker stats
```

**Optimizar velocidad:**
- llama3.2:1b ya estÃ¡ optimizado para velocidad por defecto
- Para mÃ¡s potencia: cambiar a mistral:7b-instruct
- Ajustar CHUNK_SIZE segÃºn hardware (default: 1200)
- Considerar SSD para volÃºmenes Docker

## ğŸ§ª Testing

```bash
# Ejecutar tests completos
python run_tests.py

# Tests especÃ­ficos
pytest tests/unit/                     # Tests unitarios
pytest tests/integration/              # Tests de integraciÃ³n
pytest tests/e2e/                      # Tests end-to-end

# Test de aceptaciÃ³n
python validate_acceptance_criteria.py
```

## ğŸ“Š Monitoreo y MÃ©tricas

**Endpoints de salud:**
- App: http://localhost:8080/health
- Qdrant: http://localhost:6333/healthz
- Ollama: http://localhost:11434/api/tags
- PyExec: http://localhost:8001/health

**MÃ©tricas disponibles:**
- Qdrant: Dashboard en http://localhost:6333/dashboard
- Docker: `docker compose top` y `docker stats`

## ğŸš€ Despliegue en ProducciÃ³n

### Consideraciones de Seguridad

1. **Cambiar puertos por defecto:**
   ```yaml
   ports:
     - "7861:7860"  # En lugar de 7860:7860
   ```

2. **Variables de entorno sensibles:**
   ```bash
   # Crear .env file
   echo "GRADIO_AUTH=admin:password" > .env
   ```

3. **Firewall y reverse proxy:**
   ```bash
   # Solo exponer puertos necesarios
   # Usar nginx/traefik como proxy
   ```

### Escalabilidad

```yaml
# En docker-compose.yml
deploy:
  replicas: 2
  resources:
    limits:
      memory: 2G
    reservations:
      memory: 1G
```

## ğŸ¤ Desarrollo y ContribuciÃ³n

**Estructura del proyecto:**
```
â”œâ”€â”€ app.py              # AplicaciÃ³n principal Gradio
â”œâ”€â”€ ingest.py           # Procesamiento de PDFs
â”œâ”€â”€ pyexec_service.py   # Servicio de ejecuciÃ³n Python
â”œâ”€â”€ docker-compose.yml  # ConfiguraciÃ³n de servicios
â”œâ”€â”€ Dockerfile          # Imagen multi-etapa
â”œâ”€â”€ requirements.*.txt  # Dependencias por servicio
â”œâ”€â”€ tests/              # Suite de testing
â””â”€â”€ docs/              # Documentos para ingestar
```

**Flujo de desarrollo:**
1. Fork del repositorio
2. Crear rama feature/nombre-feature
3. Desarrollar con tests
4. Ejecutar suite completa: `python run_tests.py`
5. Crear Pull Request

**EstÃ¡ndares de cÃ³digo:**
- Python: Black, isort, flake8
- Dockerfiles: Hadolint
- DocumentaciÃ³n: Markdown lint

## ğŸ“„ Licencia

[Especificar licencia del proyecto]

## ğŸ†˜ Soporte

- **Issues:** [GitHub Issues](link-to-issues)
- **DocumentaciÃ³n:** [Wiki](link-to-wiki)
- **Chat:** [Discord/Slack](link-to-chat)

---

**Ãšltima actualizaciÃ³n:** Agosto 2024 (actualizado modelo llama3.2:1b)
**VersiÃ³n:** 1.0.0
